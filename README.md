# ObjectandHumanDetection

The primary aim of this project was to train a mobile robot to recognize and track objects or humans using machine learning and deep learning methods. Using the camera integrated in an AlphaBot2-Pi robot and the necessary coding tools (e.g., ROS, Raspberry Pi, and Python) a recognition of human gestures and faces, objects and humans as a whole was to be accomplished and consequently make the robot reproduce a response. The response of the robot this thesis aimed for was not only to recognize the multiple objects and return them via a uniquely design code but also to be able to track the face of the human detected and follow it moving around accordingly. 


The project was divided in two different scripts. One written on the raspberry and the other one on a Macbook Air M1. Both scrpits are found on this repository.
